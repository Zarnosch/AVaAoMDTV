\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=25mm, right=25mm, bottom=20mm, top=25mm]{geometry}
\usepackage{pgfplots}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{parskip}
\usepackage[ngerman]{babel}
\usepackage{float}
 
\begin{document}
	\section*{Kriterien für die Lesbarkeitsanalyse}
	Die folgenden 5 Kriterien sind in der Literatur\footnote{\url{http://bib.dbvis.de/uploadedFiles/305.pdf}} durch empirische Analyse als für die Lesbarkeit bedeutsam befunden worden. Die Beschreibung zur Berechnung des Kriteriums aus den zu erhebenden Features enthält außerdem eine tabellarische Auswertung der Testergebnisse, die zur Ermittlung der Grenzwerte der Feature-Werte genutzt wurden. Dabei beschreibt der Mittelwert der min-Werte für einfache Texte die untere Grenze und der Mittelwert der max-Werte für schwere Texte die obere Grenze (außer bei \textit{Komplexität der Vokabeln}). Werte oberhalb/unterhalb dieser Grenzen werden auf das jeweilige Minimum/Maximum geclipt.
	
	\textcolor{gray}{Wird die Farbkodierung adaptiv in Bezug auf den zugrundeliegenden Maßstab für die Normalisierung (vgl. Figure 2 im Paper) implementiert, überlappen sich vermutlich die Werte des längsten Wörter in den leicht lesbaren Texten mit den Werten der kürzesten Wörter in den schwer lesbaren Texten. Es ist generell zu diskutieren, ob dieser Umstand in der Farbkodierung reflektiert werden sollte oder ob dies die Interpretation der Analyseergebnisse nicht sogar erschwert.}
	
	\subsection*{Wortlänge}
	Hierfür wird zunächst die durchschnittliche Wortlänge analysiert und normiert. 
	Sei $ W $ die Menge aller Wörter $ w_i $ im zu analysierenden Text mit Wortlänge $ |w_i| $. Die minimale Wortlänge ist 1 (bzw. 2 im Deutschen), die maximale ist $ |w_i|_{max}=max(|w_i|) $ bzgl. aller Wörter $ w_i\in W $. 
	
	Der Lesbarkeitswert jedes Wortes wird normiert durch $ \frac{|w_i|}{|w_i|_{max}}$ und der summierte Wert der Wörter des entsprechenden Satzes durch die Anzahl der Wörter $ |W| $ geteilt. Anschließend wird der Wert z.B. auf Farbwerte zwischen blau $ (32,62,181) $, weiß und rot $ (186,57,44) $ abgetragen.
		
	\begin{equation*}
		\text{Wortlänge-Wert: }\frac{1}{|W|}\cdot\sum\limits_i \frac{|w_i|-2}{4}
	\end{equation*}
		
	\subsubsection*{Skala}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline it\_could\_happen & 3.25 & 5.66 & 4.29 \\ 
			\hline the\_halloween\_house & 2.00 & 9.00 & 4.10 \\ 
			\hline the\_little\_gingerbread\_man & 2.50 & 6.33 & 4.17 \\ 
			\hline who\_did\_patricks\_homework & 2.00 & 6.00 & 3.84 \\ 
			\hline 
		\end{tabular}\right\}$ untere Grenze: $ \overline{min}=2.4375\approx 2 $
		\caption{Wortlänge: einfache Texte}
	\end{table}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline black\_and\_white & 3.50 & 6.15 & 5.00 \\ 
			\hline fight\_terrorism & 3.72 & 6.50 & 5.04 \\ 
			\hline jura\_paper & 4.52 & 6.94 & 5.55 \\ 
			\hline paper\_medicine & 3.06 & 7.55 & 5.13 \\ 
			\hline poems & 2.00 & 4.86 & 3.47 \\ 
			\hline political\_english\_text & 3.50 & 5.91 & 4.85 \\ 
			\hline 
		\end{tabular}\right\}$ obere Grenze: $ \overline{max}=6,3183\approx 6 $
		\caption{Wortlänge: schwere Texte}
	\end{table}
	\pgfplotsset{compat=1.10}
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}
			\begin{axis}[
			colormap={lolmap}{[1cm] 
				rgb255(0cm)=(32,62,181) color(5cm)=(white) rgb255(10cm)=(186,57,44)}, colorbar horizontal, colorbar/width=.5cm, 
				colorbar style={xtick={0,.5,1},
				xlabel near ticks, 
				extra x ticks={0,1},
				extra x tick labels={kurze Wörter, lange Wörter}, 
				extra x tick style={ticklabel pos=right}   
				},
				hide axis
			]
			\end{axis}
			\end{tikzpicture}
		\end{figure}
		
	\subsection*{Komplexität der Vokabeln}
	Hier wird der Prozentanteil eines Absatzes/Satzes gemessen, der nicht in einer Liste häufig verwendeter Wörter vorkommt. Dazu kann entweder Wikipedia\footnote{\url{https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists\#German}} (deutsch/englisch), ein Korpus aus Zeitungsartikeln\footnote{\url{http://wortschatz.uni-leipzig.de/html/wliste.html}} oder evtl. eine fachspezifische Textsammlung ausgewertet werden. Der Anteil der Wörter $ w_i $, die nicht in der Liste $ L $ sind, wird dann durch die Anzahl $ |W| $ der Wörter im zu analysierenden Text $ W $ geteilt. 
	
	Das Ergebnis ist also \textbf{inhärent normiert}, die Tests dienen nur der subjektiven Überprüfung der Güte der Aussagekraft des entsprechenden Wertes.
	
	\begin{equation*}
	\text{Vokabelkomplexitäts-Wert: } \frac{|w_i\not\in L|}{|W|}
	\end{equation*}
	
	\subsubsection*{Skala}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline it\_could\_happen & 0.20 & 0.75 & 0.41 \\ 
			\hline the\_halloween\_house & 0.00 & 1.00 & 0.42 \\ 
			\hline the\_little\_gingerbread\_man & 0.00 & 0.75 & 0.37 \\ 
			\hline who\_did\_patricks\_homework & 0.00 & 0.75 & 0.37 \\ 
			\hline 
		\end{tabular}\right\}$ untere Grenze: 0.00
		\caption{Komplexität der Vokabeln: einfache Texte}
	\end{table}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline black\_and\_white & 0.08 & 0.75 & 0.54 \\ 
			\hline fight\_terrorism & 0.14 & 0.71 & 0.49 \\ 
			\hline jura\_paper & 0.24 & 0.68 & 0.50 \\ 
			\hline paper\_medicine & 0.47 & 0.93 & 0.73 \\ 
			\hline poems & 0.00 & 0.64 & 0.32 \\ 
			\hline political\_english\_text & 0.16 & 0.64 & 0.45 \\ 
			\hline 
			\end{tabular}\right\}$ obere Grenze: 1.00
		\caption{Komplexität der Vokabeln: schwere Texte}
	\end{table}
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		colormap={lolmap}{[1cm] 
			rgb255(0cm)=(32,62,181) color(5cm)=(white) rgb255(10cm)=(186,57,44)}, colorbar horizontal, colorbar/width=.5cm, 
		colorbar style={xtick={0,.5,1},
			xlabel near ticks, 
			extra x ticks={0,1},
			extra x tick labels={wenige komplexe Wörter, viele komplexe Wörter}, 
			extra x tick style={ticklabel pos=right}   
		},
		hide axis
		]
		\end{axis}
		\end{tikzpicture}
	\end{figure}
	\newpage
	\subsection*{Nominalisierungskomplexität}
	Die Nominalisierung ist die Bildung eines Substantivs aus einer anderen Wortart, vor allem aus Verben und Adjektiven (z.B. \textit{das Böse, etwas Hübsches; the evil, something pretty}). Ein Gerundium ist ein substantivierter Infinitiv eines Verbs (z.b. \textit{\textbf{climbing} is dangerous; \textbf{das Klettern} ist gefährlich}).
	
	Da Nominalisierungen schwer grundsätzlich vermeidbar sind, die Lesbarkeit des Textes aber auch nicht zwingend schwer unter ihrer Verwendung leidet (z.B. \textit{Es geschah aus \textbf{Versehen}; The \textbf{use} of drugs is dangerous}), muss die Bewertungsskala kontextsensitiv angelegt werden\footnote{\url{https://ps.ipd.kit.edu/backend/index.php/veroeffentlichungen-details/items/3801.html}}. Bei einem wissenschaftlichen Fachartikel wird die Lesbarkeit bzgl. dieses Kriteriums evtl. zugunsten einer präzisen Formulierung vernachlässigt, in der Unterhaltungsliteratur wiederum als Stilmittel, etwa um eine Gesinnung über eine bestimmte Ausdrucksweise zu transportieren. Generell sind Texte mit vielen Verben leichter verständlich als Sätze mit wenigen.
	
	Die Berechnung der Nominalisierungskomplexität ergibt sich aus dem Verhältnis von Verben zu Nomen und der geschätzten Anzahl Nominalisierungen. Diese wird anhand der Endung des Wortes (z.B. -tion, -ity, \dots) ermittelt. Das entsprechende Nomen wird doppelt gezählt (Anzahl der Nominalisierungen wird zur Anzahl der Nomen addiert), um ihm mehr Gewicht zu verleihen.
	
	\begin{equation*}
		\text{Nominalisierungskomplexität: }\frac{|Verben|}{|Nomen|+|Nominalisierungen|}
	\end{equation*}
	
	\textbf{Achtung!} Hier ist ausnahmsweise ein höherer Wert besser als ein kleiner! Für die Visualisierung wird daher der normierte Kehrwert zurückgegeben.
	
	\begin{equation*}
	\text{Nominalisierungskomplexitäts-Wert: } 1-\frac{1}{4}\cdot\frac{|Verben|}{|Nomen|+|Nominalisierungen|}
	\end{equation*}
		
	
	\subsubsection*{Skala}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline it\_could\_happen & 0 & 5 & 1.00 \\ 
			\hline the\_halloween\_house & 0 & 4 & 0.76 \\ 
			\hline the\_little\_gingerbread\_man & 0 & 5 & 1.29 \\ 
			\hline who\_did\_patricks\_homework & 0 & 3 & 1.10 \\ 
			\hline 
		\end{tabular}\right\}$ obere Grenze: $ \overline{max}=4.25\approx 4 $
		\caption{Nominalisierungen: einfache Texte}
	\end{table}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline black\_and\_white & 0 & 3 & 0.45 \\ 
			\hline fight\_terrorism & 0.14 & 2.00 & 0.58 \\ 
			\hline jura\_paper & 0.00 & 1.40 & 0.49 \\ 
			\hline paper\_medicine & 0.00 & 0.75 & 0.33 \\ 
			\hline poems & 0.00 & 3.00 & 1.08 \\ 
			\hline political\_english\_text & 0.00 & 1.33 & 0.46 \\ 
			\hline 
			\end{tabular}\right\}$ untere Grenze: $ \overline{min}=0.023\approx 0 $
		\caption{Nominalisierungen: schwere Texte}
	\end{table}
	

	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		colormap={lolmap}{[1cm] 
			rgb255(0cm)=(32,62,181) color(5cm)=(white) rgb255(10cm)=(186,57,44)}, colorbar horizontal, colorbar/width=.5cm, 
		colorbar style={xtick={0,.5,1},
			xlabel near ticks, 
			extra x ticks={0,1},
			extra x tick labels={niedrige Nominalisierungskomplexität, hohe Nominalisierungskomplexität}, 
			extra x tick style={ticklabel pos=right}   
		},
		hide axis
		]
		\end{axis}
		\end{tikzpicture}
	\end{figure}
	
	\subsection*{Satzlänge}
	Hier wird die Anzahl der Wörter $ |W| $ in einem Satz gemessen. Der experimentell ermittelte Höchstwert von 100 Wörtern pro Satz verzerrt die Ergebnisse sehr stark. Die Literatur\footnote{BASTABLE, Susan B., et al. Health professional as educator: principles of teaching and learning, S. 577. Jones \& Bartlett Publishers, 2010.}$ ^, $ \footnote{\url{https://de.wikipedia.org/wiki/Satzl\%C3\%A4nge\#Durchschnittliche_Satzl.C3.A4nge}} bestätigt diesen subjektiven Eindruck. Daher wird ein Höchstwert von 29 verwendet, der sich auch in der avg-Spalte von Tabelle~\ref{sent_length_hard} wiederfindet.
		
	\begin{equation*}
		\text{Satzlänge-Wert: }\frac{|W|-2}{27}
	\end{equation*}	
	
	\subsubsection*{Skala}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline it\_could\_happen & 3 & 42 & 18.00 \\ 
			\hline the\_halloween\_house & 1 & 26 & 9.68 \\ 
			\hline the\_little\_gingerbread\_man & 3 & 31 & 10.91 \\ 
			\hline who\_did\_patricks\_homework & 2 & 21 & 10.00 \\ 
			\hline 
		\end{tabular}\right\}$ untere Grenze: $ \overline{min}=1.75\approx 2 $
		\caption{Satzlänge: einfache Texte}
	\end{table}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline black\_and\_white & 4 & 81 & 26.65 \\ 
			\hline fight\_terrorism & 11 & 52 & 25.49 \\ 
			\hline jura\_paper & 6 & 74 & 29.60 \\ 
			\hline paper\_medicine & 8 & 101 & 28.83 \\ 
			\hline poems & 2 & 54 & 17.22 \\ 
			\hline political\_english\_text & 6 & 39 & 19.15 \\ 
			\hline 
			\end{tabular}\right\}$ {tatsächliche Grenze: 29 (siehe Beschreibung oben)}
		\caption{Satzlänge: schwere Texte}
		\label{sent_length_hard}
	\end{table}
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		colormap={lolmap}{[1cm] 
			rgb255(0cm)=(32,62,181) color(5cm)=(white) rgb255(10cm)=(186,57,44)}, colorbar horizontal, colorbar/width=.5cm, 
		colorbar style={xtick={0,.5,1},
			xlabel near ticks, 
			extra x ticks={0,1},
			extra x tick labels={kurze Sätze, lange Sätze}, 
			extra x tick style={ticklabel pos=right}   
		},
		hide axis
		]
		\end{axis}
		\end{tikzpicture}
	\end{figure}
	\newpage
	\subsection*{Komplexität der Satzstruktur}
	Dieses Kriterium basiert auf der Annahme, dass der für das Verständnis eines Satzes erforderliche mentale Arbeitsaufwand mit dem Grad an Verschachtelung und der Verwendung von Klammern steigt. 
	
	Der dem Maßstab zugrundeliegende Verzweigungsfaktor des Satzstruktur-Baums muss zunächst experimentell ermittelt werden. Um Mehrdeutigkeiten aufzulösen, wird der Stanford Parser\footnote{\url{http://nlp.stanford.edu/software/lex-parser.shtml}} verwendet. Dieser hat auch eine eingebaute Visualisierungsmöglichkeit für den entstehenden Syntaxbaum.
	
	\begin{equation*}
		\text{Verschachtelungswert: } \frac{Baumtiefe-4}{20}
	\end{equation*}
		
	
	\subsubsection*{Skala}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline it\_could\_happen & 5 & 21 & 10.00 \\ 
			\hline the\_halloween\_house & 3 & 17 & 6.74 \\ 
			\hline the\_little\_gingerbread\_man & 3 & 19 & 8.08 \\ 
			\hline who\_did\_patricks\_homework & 4 & 17 & 7.36 \\ 
			\hline 
		\end{tabular}\right\}$ untere Grenze: $ \overline{min}=3.75\approx 4 $
		\caption{Komplexität der Satzstruktur: einfache Texte}
	\end{table}
	\begin{table}[H]
		$\left.\begin{tabular}{|l|r|r|r|}
			\hline Text & min & max & avg \\ 
			\hline\hline black\_and\_white & 4 & 23 & 11.84 \\ 
			\hline fight\_terrorism & 7 & 25 & 13.00 \\ 
			\hline jura\_paper & 5 & 26 & 14.40 \\ 
			\hline paper\_medicine & 5 & 24 & 11.75 \\ 
			\hline poems & 3 & 26 & 10.13 \\ 
			\hline political\_english\_text & 5 & 19 & 11.12 \\ 
			\hline 
			\end{tabular}\right\}$ obere Grenze: $ \overline{max}=23.83\approx 24 $
		\caption{Komplexität der Satzstruktur: schwere Texte}
	\end{table}
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		colormap={lolmap}{[1cm] 
			rgb255(0cm)=(32,62,181) color(5cm)=(white) rgb255(10cm)=(186,57,44)}, colorbar horizontal, colorbar/width=.5cm, 
		colorbar style={xtick={0,.5,1},
			xlabel near ticks, 
			extra x ticks={0,1},
			extra x tick labels={einfache Sätze, komplexe Sätze}, 
			extra x tick style={ticklabel pos=right}   
		},
		hide axis
		]
		\end{axis}
		\end{tikzpicture}
	\end{figure}
	
	\subsubsection*{Erläuterung}
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[
		scale=0.75,
		sibling distance        = 8em,
		level distance          = 3em,
		every node/.style = {shape=rectangle, rounded corners,
			draw, align=center},
		leaf/.style = {shape=rectangle, rounded corners,
			draw=none, align=center, color=red},
		]]

		\node(Root) {S}
		child { node {NP} 			
			child { node[leaf] {I}}
		}
		child { node {VP}
			child[level distance=2em] { node {V} 
					child { node[leaf] {shot} }
			}
			child { node {NP} 
				child { node {Det} 
					child { node[leaf] {an} 
					}
				}
				child { node {N} 
					child { node[leaf] {elephant} 
					}
				}
				child { node {PP} 
					child { node {P}
						child { node[leaf] {in} }
					}
					child { node {NP}
						child { node {Det}
							child { node[leaf] {my}}
						}
						child { node {N}
							child { node[leaf] {pajamas}}
						}
					}
				}
			}
		};
		\end{tikzpicture}
		\caption{Beispiel 1 für Mehrdeutigkeit, 6 Level}
	\end{figure}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[
			scale=0.75,
			sibling distance        = 12em,
			level distance          = 3em,
			every node/.style = {shape=rectangle, rounded corners,
				draw, align=center},
			leaf/.style = {shape=rectangle, rounded corners,
				draw=none, align=center, color=red},
			]]
			\node {S}
			child { node {NP} 			
				child { node[leaf] {I}}
			}
			child { node {VP}
				child[sibling distance=12em]  { node {VP} 
						child{ node {V} 
							child { node[leaf] {shot}}	
						}
						child [sibling distance=5em]  { node {NP} 
								child { node {Det} 
									child { node[leaf] {an}}
								}
								child { node {N} 
									child { node[leaf] {elephant}}
								}
						}
				}
				child  { node {PP} 
					child[sibling distance=5em] { node {P} 
						child { node[leaf] {in} 
						}
					}
					child { node {NP} 
						child { node {Det}
							child { node[leaf] {my} }
						}
						child { node {N}
							child { node[leaf] {pajamas}}
						}
					}
				}
		};
			\end{tikzpicture}
			\caption{Beispiel 2 für Mehrdeutigkeit, 5 Level}
		\end{figure}

	\begin{table}[H]
		\centering
		\begin{tabular}{ l|l|l }
			Symbol & Bedeutung &Beispiel\\
			\hline
			S&	sentence	&the man walked\\
			NP&	noun phrase&	a dog\\
			VP&	verb phrase&	saw a park\\
			PP&	prepositional phrase&	with a telescope\\
			Det&	determiner&	the\\
			N&	noun&	dog\\
			V&	verb&	walked\\
			P&	preposition&	in
		\end{tabular}
	\end{table}
	
\end{document}